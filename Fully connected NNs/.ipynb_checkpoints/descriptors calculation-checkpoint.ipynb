{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd48cc9a-1ce8-4c46-b82d-d035600b3555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, AllChem\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from rdkit.Chem import DataStructs\n",
    "from sklearn.impute import KNNImputer\n",
    "from feature_engine.selection import DropCorrelatedFeatures \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40057634-286c-4644-93a1-295eeca4e87a",
   "metadata": {},
   "source": [
    "First, let's upload the grouped table, which contains data on critical properties and molecules structures. We drop columns **Is_organic** and **num_fragments** as they are unnecessary now and re-make **mol** column as in .csv it turned into string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16539adf-34d7-42f0-be57-9f5cecd2a973",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_table = pd.read_csv('grouped_table.csv', index_col = 0).reset_index(drop = True).drop(columns = ['Is_organic', 'num_fragments'])\n",
    "grouped_table['mol'] = grouped_table['SMILES'].apply(lambda x: Chem.MolFromSmiles(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550aac36-6f99-4698-884d-54c6364c90b2",
   "metadata": {},
   "source": [
    "We make a function, that creates Pandas DataFrame of descriptors for list of molecules and get such a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d3561bd-7417-4ea1-bcbe-aec11dfc629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mols_to_descriptors(list_of_mols):\n",
    "    #Dicionary to be transformed into dataframe: name of descriptor : empty list\n",
    "    descriptor_dict = {desc[0]:[] for desc in Descriptors.descList }\n",
    "    for mol in tqdm(list_of_mols):\n",
    "        #descList is a tuplt: (name, function)\n",
    "        for descriptor, func in Descriptors.descList:\n",
    "            try:\n",
    "                #append numeric value or nan into the list cooresponding to descriptor's name\n",
    "                descriptor_dict[descriptor].append(func(mol))\n",
    "            except:\n",
    "                descriptor_dict[descriptor].append(np.nan)\n",
    "    return pd.DataFrame(descriptor_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d95423e5-cc3a-4b90-8e7a-f1a41cf8ce23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7104/7104 [00:40<00:00, 175.44it/s]\n"
     ]
    }
   ],
   "source": [
    "desc_df = mols_to_descriptors(grouped_table['mol'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6617ad-d766-483b-b722-3fee4742f283",
   "metadata": {},
   "source": [
    "Some of descriptors are highly correlated with others, so we use [Feature engine](https://feature-engine.trainindata.com/en/latest/) to found \"duplicative\" ones and drop them. With threshold of 0.9, we got rid of 25% descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f472ff36-ae60-4ea0-9be7-d6fb3a69760f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropping 208\n",
      "After dropping 156\n"
     ]
    }
   ],
   "source": [
    "print('Before dropping', desc_df.shape[1])\n",
    "dropper = DropCorrelatedFeatures(threshold=0.9)\n",
    "desc_df = dropper.fit_transform(desc_df)\n",
    "print('After dropping', desc_df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bae9aa-cd0d-4ac4-9577-65c02f51053f",
   "metadata": {},
   "source": [
    "Let's save the list of descriptors to drop to use it on the stage of critical properties calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb0cc49e-1fda-4ab0-9499-9abcb4e7b9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('features_to_drop.pickle', 'wb') as out:\n",
    "    pickle.dump(dropper.features_to_drop_, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fae68cb-f2e4-4a19-8ef1-5f195f776c7d",
   "metadata": {},
   "source": [
    "There can be problems with certain descriptors with certain molecules and we can get *NaN*s. To avoid problems with computation, we use simple KNNImputer to fill the gaps. Then we save imouter as it can be helpful in final calculators (*calculator_py.py* and *calculator_notebook.ipynb*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d2869c1-8b3a-4188-8c9e-8b68dd6e74dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer()\n",
    "desc_df_columns = desc_df.columns\n",
    "desc_df = pd.DataFrame(imputer.fit_transform(desc_df), columns = desc_df_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7941cf4f-dd1e-45da-af65-65d3b9381789",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('imputer.pickle', 'wb') as out:\n",
    "    pickle.dump(imputer, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bfd89a-dc2a-46fb-ba50-3e816eec9502",
   "metadata": {},
   "source": [
    "And we also create circular fingerprints of all molecules and unite them with numeric descriptors to include structural information into model. We create a function and then make separate DataFrame with fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4bfad2d-53a5-44f9-b344-6301ae364948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mols_to_fingerprints(list_of_mols):\n",
    "    #fp_list will contain all fingerprints in np_array type and will be transformed into Dataframe\n",
    "    fp_list = []\n",
    "    for mol in tqdm(list_of_mols):\n",
    "        fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius = 3)\n",
    "        #destination array that will receive numpy array of fingerprint\n",
    "        dest_array = np.zeros(2048)\n",
    "        DataStructs.ConvertToNumpyArray(fp, dest_array)\n",
    "        fp_list.append(dest_array)\n",
    "        #final dataframe contains fingerprints with columns fp1, fp2 ... fp20148 \n",
    "    return pd.DataFrame(np.stack(fp_list), columns = ['fp{}'.format(i) for i in range(2048)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8903a1df-7751-401c-9944-b047d1ed6123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7104/7104 [00:00<00:00, 9218.16it/s]\n"
     ]
    }
   ],
   "source": [
    "fp_df = mols_to_fingerprints(grouped_table['mol'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f35fe4c-250b-48dd-9e2c-554be674fa78",
   "metadata": {},
   "source": [
    "Then we just concatenate tables with descriptors and fingerprints and save it as *table_with_descriptors.csv*, which will be used during following work with fully connected NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b00f167c-828b-41db-8ffa-6da74dba5c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_table = pd.concat([grouped_table.reset_index(drop = True), desc_df, fp_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9a35b3b9-a514-486c-aad0-c709ff14e20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_table.to_csv('table_with_desriptors.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
